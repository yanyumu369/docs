## 1.1 计算机与算法

### 1.1.3 冒泡排序

D. Knuth 曾指出，四分之一以上的 CPU 时间都用于执行同一类型的计算：按照某种约定的次序，将给定的一组元素**顺序排列**，比如将 n 个整数按通常的大小次序排成一个非降序列。这类操作统称**排序**（sorting）。就广义而言，我们今天借助计算机所完成的计算任务中，有更高的比例都可归入此类。例如，从浩如烟海的万维网中找出与特定关键词最相关的前 100 个页面，就是此类计算的一种典型形式。排序问题在算法设计与分析中扮演着重要的角色。

#### 局部有序和整体有序

在由一组整数组成的序列 $A[0, n-1]$ 中，满足 $A[i-1] \le A[i]$ **的相邻元素称作顺序的**；否则是**逆序**的。不难看出，有序序列中每一对相邻元素都是顺序的，亦即，对任意 $1 \le i < n$ 都有 $A[i-1] \le A[i]$；反之，所有相邻元素均顺序的序列，也必然整体有序。

#### 扫描交换

由有序序列的上述特征，我们可以通过不断改善局部的有序性实现整体的有序：**从前向后依次检查每一对相邻元素，一旦发现逆序即交换二者的位置**。对于长度为 $n$ 的序列，共需做 $n-1$ 次比较和不超过 $n-1$ 次交换，这一过程称作**一趟扫描交换**。

<div align=center>
<img width="70%" src="computer_science\data_structure\数据结构_邓俊辉\image\通过扫描交换进行排序.png"/><br>
</div>

#### 冒泡排序

可见，经过这样的一趟扫描，序列未必达到整体有序。因此，需要对该序列反复进行多次扫描交换，直到在序列中不再含有任何逆序的相邻元素。多数的这类交换操作，都会使得越小（大）的元素朝上（下）方移动，直至它们抵达各自应处的位置。排序过程中，所有元素朝各自最终位置亦步亦趋的移动过程，犹如气泡在水中的上下沉浮，**冒泡排序**冒泡排序（bubblesort）算法也因此得名。

#### 实现

```cpp
// 代码 1.1 整数数组的冒泡排序
#include <algorithm>

void bubblesort1A(int A[], int n) {         //冒泡排序算法（版本 1A）：0 <= n
    bool sorted = false;                    //整体排序标志，首先假定尚未排序
    while (!sorted) {                       //在尚未确认已全局排序之前，逐趟进行扫描交换
        sorted = true;                      //假定已经排序
        for (int i = 1; i < n; i++) {       //自左向右逐对检查当前范围 A[0, n) 内的各相邻元素
            if (A[i - 1] > A[i]) {          //一旦 A[i - 1] 与 A[i] 逆序，则
                std::swap(A[i - 1], A[i]);  //交换之，并
                sorted = false;             //因整体排序不能保证，需要清除排序标志
            }
        }
        n--;                                //至此末元素必然就位，故可以缩短待排序序列的有效长度
    }
}                                           //借助布尔型标志位 sorted，可及时提前退出，而不致总是蛮力地做 n - 1 趟扫描交换

```

### 算法

究竟什么是算法呢？所谓算法，是指基于特定的计算模型，旨在解决某一信息处理问题而设计的一个**指令序列**。

一般地，本书所说的算法还应必须具备以下要素。

#### 输入和输出

待计算问题的任一实例，都需要以某种方式交给对应的算法，对所求解问题特定实例的这种描述统称为**输入**（input）。

#### 基本操作、确定性和可行性

所谓**确定性**和**可行性**是指，算法应可描述为由若干语义明确的基本操作组成的指令序列，且每一基本操作在对应的计算模型中均可兑现。

从现代程序设计语言的角度，可以更加便捷而准确地理解算法的确定性与可行性。具体地，一个算法满足确定性与可行性，当且仅当它可以通过程序设计语言精确地描述，比如，冒泡排序算法可以具体地描述和实现为代码 1.1 中的函数 `bubblesort1A()`，其中“读取某一元素的内容”、“修改某一元素的内容”、“比较两个元素的大小”、“逻辑表达式求值”以及“根据逻辑判断确定分支转向”等等，都属于现代电子计算机所支持的基本操作。

#### 有穷性与正确性

不难理解，任意算法都应在执行有限次基本操作之后终止并给出输出，此即所谓算法的**有穷性**（finiteness）。进一步地，算法不仅应该迟早会终止，而且所给的输出还应该能够符合由问题本身在事先确定的条件，此即所谓算法的**正确性**（correctness）。

#### 冒泡排序

证明算法有穷性和正确性的一个重要技巧，就是从适当的角度审视整个计算过程，并找出其所具有的某种**不变性**和单调性**单调性**。其中的**单调性**通常是指，问题的有效规模会随着算法的推进不断递减。**不变性**则不仅应在算法初始状态下自然满足，而且应与最终的正确性相呼应—当问题的有效规模缩减到 0 时，不变性应随即等价于正确性。

于是，冒泡排序算法的**不变性**和**单调性**可分别概括为：经过 $k$ 趟扫描交换之后，最大的前 $k$ 个元素必然就位；经过 $k$ 趟扫描交换之后，待求解问题的有效规模将缩减至 $n-k$。

#### 退化与鲁棒性

同一问题往往不限于一种算法，而同一算法也常常会有多种实现方式，因此除了以上必须具备的基本属性，在应用环境中还需从实用的角度对不同算法及其不同版本做更为细致考量和取舍。这些细致的要求尽管应纳入软件工程的范畴，但也不失为成熟算法的重要标志。

比如其中之一就是，除一般性情况外，实用的算法还应能够处理各种极端的输入实例。仍以排序问题为例，极端情况下待排序序列的长度可能不是正数（参数 $n=0$ 甚至 $n<0$），或者反过来长度达到或者超过系统支持的最大值（$n=INT_MAX$），或者 $A[]$ 中的元素不见得互异甚至全体相等，以上种种都属于所谓的**退化**（degeneracy）情况。算法所谓的**鲁棒性**（robustness），就是要求能够尽可能充分地应对此类情况。对于以上退化情况，代码 1.1 中 `bubblesort1A()` 算法依然可以正确返回而不致出现异常。

#### 重用性

从实用角度评判不同算法及其不同实现方式时，可采用的另一标准是：**算法的总体框架能否便捷地推广至其它场合**。仍以冒泡排序为例。实际上，冒泡算法的正确性与所处理序列中元素的类型关系不大，无论是对于 `float`、`char` 或其它类型，只要元素之间可以比较大小，算法的整体框架就依然可以沿用。算法模式可推广并适用于不同类型基本元素的这种特性，即是重用性的一种典型形式。很遗憾，代码 1.1 所实现的 `bubblesort1A()` 算法尚不满足这一要求；而稍后的第 2 章和第 3 章，将使包括冒泡排序在内的各种排序算法具有这一特性。

### 1.1.5 算法效率

#### 可计算性

以前面提到的有穷性为例，完全合乎语法的程序却往往未必能够满足。相信每一位编写过程序的读者都有过这样的体验：很多合法的程序可以顺利编译链接，但在实际运行的过程中却因无穷循环或递归溢出导致异常。更糟糕的是，就大量的应用问题而言，根本就不可能设计出必然终止的算法。从这个意义讲，它们都属于不可解的问题。当然，关于此类问题的界定和研究，应归入**可计算性**（computability）理论的范畴，本书将不予过多涉及。

#### 难解性

实际上我们不仅需要确定，算法对任何输入都能够在有穷次操作之后终止，而且更加关注该过程所需的时间。很遗憾，很多算法即便满足有穷性，但在终止之前所花费的时间成本却太高。比如，理论研究的成果显示，大量问题的最低求解时间成本，都远远超出目前实际系统所能提供的计算能力。同样地，此类**难解性**（intractability）问题，在本书中也不予过多讨论。

#### 计算效率

在“编写合法程序”这一基础之上，本书将更多地关注于非“不可解和难解”的一般性问题，并讨论如何高效率地解决这一层面的计算问题。为此，首先需要确立一种**尺度**，用以从时间和空间等方面度量算法的计算成本，进而依此尺度对不同算法进行比较和评判。当然，更重要的是研究和归纳算法设计与实现过程中的一般性规律与技巧，以编写出效率更高、能够处理更大规模数据的程序。这两点既是本书的基本主题，也是贯穿始终的主体脉络。

#### 数据结构

由上可知，无论是算法的初始输入、中间结果还是最终输出，在计算机中都可以数据的形式表示。对于数据的存储、组织、转移及变换等操作，不同计算模型和平台环境所支持的具体形式不尽相同，其执行效率将直接影响和决定算法的整体效率。数据结构这一学科正是以“数据”这一信息的表现形式为研究对象，旨在建立支持高效算法的数据信息处理策略、技巧与方法。要做到根据实际应用需求自如地设计、实现和选用适当的数据结构，必须首先对算法设计的技巧以及相应数据结构的特性了然于心，这些也是本书的重点与难点。

## 1.2 复杂度度量

算法的计算成本涵盖诸多方面，为确定计算成本的度量标准，我们不妨先从计算速度这一主要因素入手。具体地，如何度量一个算法所需的计算时间呢？

### 1.2.1 时间复杂度

上述问题并不容易直接回答，原因在于，运行时间是由多种因素综合作用而决定的。首先，即使是同一算法，对于不同的输入所需的运行时间并不相同。以排序问题为例，输入序列的规模、其中各元素的数值以及次序均不确定，这些因素都将影响到排序算法最终的运行时间。为针对运行时间建立起一种可行、可信的评估标准，我们不得不首先考虑其中最为关键的因素。其中，问题**实例的规模往往是决定计算成本的主要因素**。一般地，问题规模越接近，相应的计算成本也越接近；而随着问题规模的扩大，计算成本通常也呈上升趋势。

如此，本节开头所提的问题即可转化为：随着输入规模的扩大，算法的执行时间将如何增长？**执行时间**的这一变化趋势可表示为**输入规模**的一个函数，称作该**算法的时间复杂度**（time complexity）。具体地，特定算法处理规模为 $n$ 的问题所需的时间可记作 $T(n)$。

细心的读者可能注意到，根据规模并不能唯一确定具体的输入，规模相同的输入通常都有多个，而算法对其进行处理所需时间也不尽相同。仍以排序问题为例，由 $n$ 个元素组成的输入序列有 $n!$ 种，有时所有元素都需交换，有时却无需任何交换。故严格说来，以上定义的 $T(n)$ 并不明确。为此需要再做一次简化，即从保守估计的角度出发，在规模为 $n$ 的所有输入中选择执行时间最长者作为 $T(n)$，并以 $T(n)$ 度量该算法的时间复杂度。

### 1.2.2 渐进复杂度

至此，对于同一问题的两个算法 $A$ 和 $B$，通过比较其时间复杂度 $T_{\rm{A}}(n)$ 和 $T_{\rm{B}}(n)$，即可评价二者对于同一输入规模 $n$ 的计算效率高低。然而，藉此还不足以就其性能优劣做出总体性的评判，比如对于某些问题，一些算法更适用于小规模输入，而另一些则相反。

幸运的是，在评价算法运行效率时，我们往往可以忽略其处理小规模问题时的能力差异，转而关注其在处理更大规模问题时的表现。其中的原因不难理解，小规模问题所需的处理时间本来就相对更少，故此时不同算法的实际效率差异并不明显；而在处理更大规模的问题时，效率的些许差异都将对实际执行效果产生巨大的影响。**这种着眼长远**、**更为注重时间复杂度的总体变化趋势和增长速度**的策略与方法，即所谓的**渐进分析**（asymptotic analysis）。那么，**针对足够大的输入规模** $n$，算法执行时间 $T(n)$ 的**渐进增长速度**，应如何度量和评价呢？

#### 大 O 记号

同样地出于保守的估计，我们首先关注 $T(n)$ 的渐进上界。为此可引入所谓“大 $O$ 记号”（big-$O$ notation）。具体地，若存在正的常数 $c$ 和函数 $f(n)$，使得对任何 $n \gg 2$ 都有
$$T(n) \le c \cdot f(n)$$
则可认为在 $n$ 足够大之后，$f(n)$ 给出了 $T(n)$ 增长速度的一个**渐进上界**。此时，记之为：
$$T(n) = O(f(n))$$
由这一定义，可导出大 $O$ 记号的以下性质：

1. 对于任一常数 $c > 0$，有 $O(f(n)) = O(c \cdot f(n))$
2. 对于任意常数 $a > b > 0$，有 $O(n^a+ n^b) = O(n^a)$

前一性质意味着，在大 $O$ 记号的意义下，函数各项正的常系数可以忽略并等同于 1。后一性质则意味着，多项式中的低次项均可忽略，只需保留最高次项。可以看出，大 $O$ 记号的这些性质的确体现了对函数总体渐进增长趋势的关注和刻画。

#### 环境差异

在实际环境中直接测得的执行时间 $T(n)$，虽不失为衡量算法性能的一种指标，但作为评判不同算法性能优劣的标准，其可信度值得推敲。事实上，即便是同一算法、同一输入，在不同的硬件平台上、不同的操作系统中甚至不同的时间，所需要的计算时间都不尽相同。因此，有必要按照超脱于具体硬件平台和软件环境的某一客观标准，来度量算法的时间复杂度，并进而评价不同算法的效率差异。

#### 基本操作

一种自然且可行的解决办法是，**将时间复杂度理解为算法中各条指令的执行时间之和**。在图灵机**图灵机**（Turing Machine, TM）和**随机存储机**（Random Access Machine, RAM）等计算模型中，指令语句均可分解为若干次基本操作，比如算术运算、比较、分支、子程序调用与返回等；而在大多数实际的计算环境中，每一次这类基本操作都**可在常数时间内完成**。

如此，不妨将 $T(n)$ 定义为**算法所执行基本操作的总次数**。也就是说，$T(n)$ 决定于**组成算法的所有语句各自的执行次数，以及其中所含基本操作的数目**。以代码 1.1 中起泡排序` bubblesort1A()` 算法为例，若将该算法处理长度为 $n$ 的序列所需的时间记作 $T(n)$，则按照上述分析，只需统计出该算法所执行基本操作的总次数，即可确定 $T(n)$ 的上界。

#### 冒泡排序

`bubblesort1A()` 算法由内、外两层循环组成。内循环从前向后，依次比较各对相邻元素，如有必要则将其交换。故在每一轮内循环中，需要扫描和比较 $n-1$ 对元素，至多需要交换 $n-1$ 对元素。元素的比较和交换，都属于基本操作，故每一轮内循环至多需要执行 $2(n-1)$ 次基本操作。另外，根据 1.1.4 节对该算法正确性的分析结论，外循环至多执行 $n-1$ 轮。因此，总共需要执行的基本操作不会超过 $2(n-1)^2$ 次。若以此来度量该算法的时间复杂度，则有
$$T(n) = O(2(n-1)^2)$$
根据大 O 记号的性质，可进一步简化和整理为：
$$T(n) = O(2n^2- 4n + 2) = O(2n^2) = O(n^2)$$

#### 最坏、最好与平均情况

由上可见，以大 $O$ 记号形式表示的时间复杂度，实质上是对算法执行时间的一种保守估计—对于规模为 $n$ 的任意输入，算法的运行时间都不会超过 $O(f(n))$。比如，“起泡排序算法复杂度 $T(n) = O(n^2)$”意味着，该算法处理任何序列所需的时间绝不会超过 $O(n^2)$。的确需要这么长计算时间的输入实例，称作最坏实例或最坏情况（worst case）。

需强调的是，这种保守估计并不排斥更好情况甚至最好情况（best case）的存在和出现。比如，对于某些输入序列，起泡排序算法的内循环的执行轮数可能少于 $n-1$，甚至只需执行一轮。当然，有时也需要考查所谓的平均情况（average case），也就是按照某种约定的概率分布，将规模为 $n$ 的所有输入对应的计算时间加权平均。

比较而言，“最坏情况复杂度”是人们最为关注且使用最多的，在一些特殊的场合甚至成为唯一的指标。比如控制核电站运转、管理神经外科手术室现场的系统而言，从最好或平均角度评判算法的响应速度都不具有任何意义，在最坏情况下的响应速度才是唯一的指标。

#### 大 Ω 记号

为了对算法的复杂度最好情况做出估计，需要借助另一个记号。如果存在正的常数 $c$ 和函数 $g(n)$，使得对于任何 $n \gg 2$ 都有
$$T(n) \ge c \cdot g(n)$$
就可以认为，在 n 足够大之后，g(n)给出了 T(n)的一个渐进下界。此时，我们记之为：
$$T(n) = \Omega(g(n))$$
这里的 $\Omega$ 称作“大 $\Omega$ 记号”（big-omega notation）。与大 $O$ 记号恰好相反，大 $\Omega$ 记号是对算法执行效率的**乐观估计**—对于规模为 $n$ 的任意输入，算法的运行时间都不低于 $\Omega(g(n))$。比如，即便在最好情况下，起泡排序也至少需要 $T(n) = \Omega(n)$ 的计算时间。

#### 大 Θ 记号

借助大 $O$ 记号、大 $\Omega$ 记号，可以对算法的时间复杂度作出定量的界定，亦即，从渐进的趋势看，$T(n)$ 介于 $\Omega(g(n))$与 $O(f(n))$ 之间。若恰巧出现 $g(n)=f(n)$的情况，则可以使用另一记号来表示。

如果存在正的常数 $c_1 < c_2$ 和函数 $h(n)$，使得对于任何 $n \gg 2$ 都有
$$c_1 \cdot h(n) \le T(n) \le c_2 \cdot h(n)$$
就可以认为在 $n$ 足够大之后，$h(n)$ 给出了 $T(n)$ 的一个确界。此时，我们记之为：
$$T(n) = \Theta(h(n))$$

这里的 $\Theta$ 称作“大 $\Theta$ 记号”（big-theta notation），它是对算法复杂度的准确估计—对于规模为 $n$ 的任何输入，算法的运行时间 $T(n)$ 都与 $\Theta(h(n))$ 同阶。

<div align=center>
<img width="70%" src="computer_science\data_structure\数据结构_邓俊辉\image\时间复杂度记号.png"/><br>
</div>

以上主要的这三种渐进复杂度记号之间的联系与区别，可直观地由图 1.4 示意。

### 1.2.3 空间复杂度

除了执行时间的长短，算法所需存储空间的多少也是衡量其性能的一个重要方面，此即所谓的**空间复杂度**（space complexity）。实际上，以上针对时间复杂度所引入的几种渐进记号，也适用于对空间复杂度的度量，其原理及方法基本相同，不再赘述。

需要注意的是，为了更为客观地评价算法性能的优劣，<mark>除非特别申明，空间复杂度通常并不计入原始输入本身所占用的空间</mark>—对于同一问题，这一指标对任何算法都是相同的。反之，其它（如**转储**、**中转**、**索引**、**映射**、**缓冲**等）各个方面所消耗的空间，则都应计入。

另外，很多时候我们都是更多地甚至仅仅关注于算法的时间复杂度，而不必对空间复杂度做专门的考查。这种简便评测方式的依据，来自于以下事实：**就渐进复杂度的意义而言，在任一算法的任何一次运行过程中所消耗的存储空间，都不会多于其间所执行基本操作的累计次数**。实际上根据定义，每次基本操作所涉及的存储空间，都不会超过常数规模；纵然每次基本操作所占用或访问的存储空间都是新开辟的，整个算法所需的空间总量，也不过与基本操作的次数同阶。从这个意义上说，时间复杂度本身就是空间复杂度的一个天然的上界。

当然，对空间复杂度的分析也有其自身的意义，尤其在对空间效率非常在乎的应用场合中，或当问题的输入规模极为庞大时，由时间复杂度所确立的平凡上界已经难以令人满意。这类情况下，人们将更为精细地考查不同算法的空间效率，并尽力在此方面不断优化。本书的后续章节，将结合一些实际问题介绍相关的方法与技巧。

## 1.3 复杂度分析

在明确了算法复杂度的度量标准之后，如何分析具体算法的复杂度呢？1.2.2 节所引入的三种记号中，大 $O$ 记号是最基本的，也是最常用到的。从渐进分析的角度，大 $O$ 记号将各算法的复杂度由低到高划分为**若干层次级别**。以下依次介绍若干典型的复杂度级别，并介绍主要的分析方法与技巧。

### 1.3.1 常数 O(1)

#### 问题与算法

考查如下常规元素的选取问题，该问题一种解法如算法 1.3 所示。

```cpp
ordinaryElement(s[], n)         // 从 n>=3 个互异整数中，除最大、最小者以外，任取一个“常规元素”
    任取的三个元素 x, y, z ∈ S; // 这三个元素亦必互异
    通过比较，对它们做排序;      // 设经排序后，一次重命名为：a < b < c
    输出 b;
```

该算法的正确性不言而喻，但它需要运行多少时间？与输入的规模 $n$ 有何联系？

#### 复杂度

既然 $S$ 是有限集，故其中的最大、最小元素各有且仅有一个。因此，无论 $S$ 的规模有多大，在任意三个元素中至少都有一个是非极端元素。不妨取前三个元素 $x = S[0]$、$y = S[1]$ 和 $z = S[2]$，这一步只需执行三次（从特定单元读取元素的）基本操作，耗费 $O(3)$ 时间。接下来，为确定这三个元素的大小次序，最多需要做三次比较，也需 $O(3)$ 时间。最后，输出居中的非极端元素只需 $O(1)$ 时间。因此综合起来，算法 1.3 的运行时间为：
$$T(n) = O(3) + O(3) + O(1) = O(7) = O(1)$$

运行时间可**表示**和**度量**为 $T(n) = O(1)$ 的这一类算法，统称作“**常数时间复杂度算法**”（constant-time algorithm）。此类算法已是最为理想的，因为不可能奢望“不劳而获”。

一般地，**仅含一次或常数次基本操作的算法**均属此类。此类算法通常不含循环、分支、子程序调用等，但也不能仅凭语法结构的表面形式一概而论。

采用 1.2.3 节的分析方法不难看出，除了输入数组等参数之外，该算法仅需常数规模的辅助空间。此类仅需 $O(1)$ 辅助空间的算法，亦称作**就地算法**（in-place algorithm）。
